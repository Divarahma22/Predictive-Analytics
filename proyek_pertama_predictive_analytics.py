# -*- coding: utf-8 -*-
"""Proyek Pertama : Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LT-9rfNonAStiA_PU0CcGXyw9yocVbIJ

# **Analisis Performa Fisik Individu**

Notebook ini dibuat untuk memprediksi tingkat performa fisik seseorang berdasarkan data antropometri (seperti tinggi, berat, dan usia), serta hasil dari berbagai tes kebugaran (seperti grip force, sit-ups, dan broad jump). Tujuan utama proyek ini adalah:

Membangun model machine learning untuk mengklasifikasikan tingkat kebugaran individu ke dalam kelas A, B, C, atau D.

Melakukan analisis terhadap fitur-fitur fisik yang paling berkontribusi dalam menentukan performa tubuh.

Memberikan insight tentang bagaimana faktor-faktor seperti usia, jenis kelamin, dan tekanan darah berkorelasi dengan kebugaran.

Dataset yang digunakan berisi 13.393 sampel data kuantitatif dan diperoleh dari sumber terbuka. Setiap baris data mewakili satu individu dengan berbagai fitur yang menggambarkan kondisi fisik dan performa dalam beberapa jenis tes kebugaran.

# **Import Library**

Sebelum memulai analisis, beberapa library diimpor untuk membantu proses pengolahan data dan pembuatan model. Pandas digunakan untuk membaca dan memanipulasi data, NumPy untuk operasi numerik, serta Matplotlib dan Seaborn untuk membuat visualisasi. Library Scikit-learn digunakan untuk membuat dan mengevaluasi model machine learning. Dengan library ini, proses analisis menjadi lebih mudah dan efisien.
"""

from google.colab import userdata
import os
import random
import textwrap
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from xgboost import XGBClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""# **Load Data**

Tahap awal dalam proyek ini adalah memuat data ke dalam notebook menggunakan library pandas. Tujuan dari proses ini adalah untuk membaca dataset dari file .csv agar bisa diolah dan dianalisis lebih lanjut. Dengan memuat data, kita dapat melihat struktur awal dataset, memastikan data berhasil dibaca dengan benar, dan mulai melakukan eksplorasi serta pra-pemrosesan. Langkah ini penting sebagai dasar untuk seluruh proses analisis dan pemodelan machine learning berikutnya.
"""

# Load dataset
df = pd.read_csv('bodyPerformance.csv')

# Tampilkan 5 baris pertama untuk memastikan data berhasil dimuat
df.head()

"""**df.info()**

**Digunakan untuk menampilkan informasi umum mengenai dataset, termasuk jumlah baris, nama kolom, tipe data, jumlah nilai yang tidak kosong, serta estimasi penggunaan memori.**
"""

df.info()

"""**Missing Values (Nilai Hilang)**

**Nilai-nilai yang kosong (null / NaN) di dataset dan perlu ditangani agar tidak menyebabkan error saat analisis atau pemodelan.**
"""

print("\nJumlah missing value di setiap kolom:")
print(df.isnull().sum())

"""**Nilai Unik (Unique Values)**

**Jumlah nilai berbeda dalam satu kolom ‚Äî penting untuk memahami variasi data.**


"""

print("\nJumlah nilai unik di setiap kolom:")
print(df.nunique())

"""**df.describe()**

**Menyajikan ringkasan statistik deskriptif untuk kolom numerik (atau semua kolom jika include='all').**
"""

df.describe()

"""# **Exploratory Data Analysis (EDA)**

**memahami distribusi nilai dari semua fitur numerik dalam dataset.**

Tahapan ini penting untuk mengetahui bagaimana data tersebar, mendeteksi kemungkinan adanya nilai ekstrem (outlier), serta memahami karakteristik umum dari setiap fitur numerik. Dengan melakukan visualisasi seperti histogram, kita dapat melihat apakah data memiliki distribusi normal, skewed, atau bahkan bimodal. Informasi ini menjadi dasar penting dalam menentukan strategi pra-pemrosesan dan pengambilan keputusan selanjutnya dalam pemodelan atau analisis
"""

# Load dataset
df = pd.read_csv("bodyPerformance.csv")

# Pilih semua kolom numerik
numeric_cols = df.select_dtypes(include=['number']).columns.tolist()

# Plot histogram dengan warna pink
df[numeric_cols].hist(bins=20, figsize=(15, 10), color='pink')
plt.tight_layout()
plt.show()

"""üìä Distribusi Fitur-Fitur Fisik dalam Dataset
Visualisasi histogram di atas menampilkan distribusi dari berbagai fitur numerik yang berkaitan dengan performa tubuh, termasuk:

1. Age (Usia)
Distribusi usia terlihat cukup merata namun sedikit condong ke kanan (right-skewed), dengan sebagian besar data berada antara usia 20 hingga 35 tahun. Ini menunjukkan bahwa mayoritas peserta dalam dataset ini adalah orang dewasa muda.

2. Height dan Weight (Tinggi dan Berat Badan)

*   Tinggi badan (height_cm) terdistribusi normal dengan puncak sekitar 170‚Äì175 cm, menandakan tinggi peserta cenderung seragam.
*   Berat badan (weight_kg) juga mendekati distribusi normal, walau ada beberapa outlier yang menunjukkan berat lebih ekstrem, baik rendah maupun tinggi.

3. Body Fat (%)
Distribusi persentase lemak tubuh menunjukkan sedikit skew ke kanan, dengan banyak peserta memiliki lemak tubuh antara 15% hingga 25%. Ada juga peserta dengan persentase lemak sangat tinggi, yang bisa menjadi perhatian dalam konteks kesehatan.

4. Tekanan Darah (Diastolic dan Systolic)
Distribusi tekanan darah diastolic dan systolic terlihat agak menyebar, namun kebanyakan berada dalam rentang sehat. Beberapa nilai tinggi dapat mengindikasikan risiko hipertensi pada sebagian peserta.

5. Grip Force & Sit and Bend Forward

*   Grip Force (kekuatan genggaman) menunjukkan sebaran yang cukup lebar, menandakan variasi besar dalam kekuatan otot peserta.
*   Sit and Bend Forward (fleksibilitas) juga beragam, menunjukkan bahwa fleksibilitas tidak merata di antara peserta.

6. Sit-ups dan Broad Jump

*   Sit-ups counts menunjukkan pola distribusi normal, dengan kebanyakan peserta mampu melakukan 40‚Äì60 sit-up.
*   Broad Jump (lompat jauh) juga terdistribusi normal, tapi dengan range yang cukup lebar, mencerminkan perbedaan kekuatan eksplosif antara individu

# **Insight Utama:**
1.Mayoritas peserta berada dalam kondisi fisik rata-rata yang sehat, terutama dalam hal tinggi, berat, dan tekanan darah.

2.Ada variasi signifikan pada aspek kekuatan otot (grip force) dan fleksibilitas, yang bisa mencerminkan perbedaan gaya hidup atau latar belakang aktivitas fisik.

3.Beberapa peserta menunjukkan nilai ekstrem (tinggi atau rendah) pada indikator lemak tubuh dan tekanan darah, yang bisa jadi indikator risiko kesehatan.

4.Data ini sangat berguna untuk mengklasifikasikan performa tubuh atau mengembangkan model prediksi tingkat kebugaran berdasarkan variabel numerik.

**Visualisasi Fitur Kategorikal**
"""

# Misalnya data kamu ada di file 'data.csv'
df = pd.read_csv("bodyPerformance.csv")

# Daftar kolom kategorikal
categorical_features = ['class', 'gender']

# Visualisasi distribusi kategori untuk setiap kolom
for col in categorical_features:
    plt.figure(figsize=(6, 4))  # Menentukan ukuran grafik
    sns.countplot(data=df, x=col, palette='Set2')  # Membuat countplot
    plt.title(f'Distribusi {col}')  # Judul grafik
    plt.xticks(rotation=45)  # Rotasi label sumbu x
    plt.tight_layout()  # Agar layout tidak terpotong
    plt.show()  # Menampilkan grafik

"""**Korelasi Antar Parameter Performa Tubuh**"""

# Membaca dataset
df = pd.read_csv("bodyPerformance.csv")

# Menentukan kolom numerik (berdasarkan info yang kamu kasih)
numeric_cols = [
    'age', 'height_cm', 'weight_kg', 'body fat_%',
    'diastolic', 'systolic', 'gripForce',
    'sit and bend forward_cm', 'sit-ups counts', 'broad jump_cm'
]

# Visualisasi korelasi antar kolom numerik
plt.figure(figsize=(10, 8))
sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='pink', fmt=".2f", linewidths=0.5)
plt.title('Korelasi Antar Parameter Performa Tubuh', fontsize=14)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

"""**Analisis Hubungan Fitur Kategorikal dengan Performa Tubuh**"""

# Misalnya data kamu ada di file 'bodyPerformance.csv'
df = pd.read_csv('bodyPerformance.csv')
# Fitur kategorikal yang akan dianalisis
categorical_features = ['gender', 'class']  # Kolom kategorikal: gender dan class

# Fitur numerik yang ingin dianalisis
performance_columns = ['body fat_%', 'gripForce', 'sit-ups counts', 'broad jump_cm']  # Kolom performa tubuh

# Visualisasi hubungan antara fitur kategorikal dan parameter performa tubuh
for feature in categorical_features:
    for performance in performance_columns:
        plt.figure(figsize=(8, 6))
        sns.boxplot(x=df[feature], y=df[performance], palette='Set2')
        plt.title(f'Perbandingan {performance} Berdasarkan {feature}')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# Alternatif visualisasi dengan violinplot untuk melihat distribusi lebih detail
for feature in categorical_features:
    for performance in performance_columns:
        plt.figure(figsize=(8, 6))
        sns.violinplot(x=df[feature], y=df[performance], palette='Set2')
        plt.title(f'Distribusi {performance} Berdasarkan {feature}')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

"""üí° 1. Perbedaan Komposisi Tubuh Berdasarkan Gender
Dari visualisasi seperti boxplot atau violinplot, kita bisa melihat:

Persentase lemak tubuh (body fat_%) cenderung lebih tinggi pada perempuan dibanding laki-laki.

üí¨ Insight: Ini konsisten dengan fisiologi biologis, karena wanita secara alami memiliki lebih banyak lemak tubuh esensial.

Kekuatan genggaman (gripForce) lebih tinggi pada laki-laki.

üí¨ Insight: Secara umum, laki-laki memiliki massa otot lebih banyak, sehingga grip force cenderung lebih kuat.

üí° 2. Performa Fisik vs Kategori Kesehatan (Class)
Jika class menunjukkan tingkat kebugaran atau klasifikasi seperti "Low", "Medium", "High":

Peserta dengan kelas "High" memiliki nilai gripForce, jumlah sit-up, dan jarak loncatan lebih tinggi dibanding kelas "Low" atau "Medium".

üí¨ Insight: Korelasi antara kebugaran dan hasil pengukuran fisik kuat. Artinya, klasifikasi class cukup menggambarkan performa tubuh seseorang.

Persentase lemak tubuh (body fat_%) menurun seiring peningkatan kelas.

üí¨ Insight: Lemak tubuh rendah cenderung dikaitkan dengan kebugaran yang lebih tinggi.

üí° 3. Sit-up dan Loncat Jauh Mencerminkan Kondisi Umum
Jumlah sit-up dan jarak broad jump bisa menjadi indikator yang baik untuk kebugaran tubuh secara umum karena:

Nilainya meningkat pada individu dari kelas yang lebih tinggi.

Nilainya lebih rendah pada individu dengan body fat_% tinggi.

üí¨ Insight: Sit-up dan broad jump bisa dijadikan parameter penting dalam pengukuran performa tubuh.

üí° 4. Gender Berpengaruh terhadap Semua Parameter
Semua parameter fisik utama seperti:

Grip force

Sit-up

Broad jump

Body fat

... menunjukkan perbedaan yang signifikan antara gender. Maka, untuk model klasifikasi atau prediksi, gender harus dimasukkan sebagai fitur karena pengaruhnya nyata terhadap hasil.

üí° 5. Korelasi antar Parameter Fisik (dari Heatmap)
Jika sebelumnya kamu juga menampilkan heatmap korelasi, biasanya akan terlihat:

Korelasi positif antara:

gripForce dan sit-ups counts

gripForce dan broad jump_cm

Korelasi negatif antara:

body fat_% dan performa fisik lain (semakin tinggi lemak, semakin rendah performanya)

üí¨ Insight: Parameter-parameter tersebut saling mendukung dan bisa dipakai untuk membentuk skor kebugaran terpadu.


---


**Kesimpulan Umum**
Fitur gender dan class sangat berpengaruh terhadap performa tubuh.

Lemak tubuh yang tinggi berkaitan dengan performa fisik yang lebih rendah.

Kekuatan otot dan kemampuan aerobik (sit-up, loncat jauh) meningkat seiring dengan kelas kebugaran.

Korelasi antar fitur fisik cukup kuat dan logis secara medis/fisiologis.

# **Data Preparation**

Pada proses ini, dataset bodyPerformance.csv diolah dengan menambahkan kolom baru bernama Performa_Baik. Kolom ini berisi nilai 1 jika nilai broad jump_cm seseorang ‚â• 220 cm, dan 0 jika di bawahnya, sebagai indikator apakah performa lompat jauh seseorang termasuk baik atau tidak. Selanjutnya, kolom-kolom kategorikal seperti gender dan class diubah menjadi bentuk numerik menggunakan One-Hot Encoding, agar bisa diproses oleh algoritma machine learning. Setelah itu, data dibagi menjadi dua bagian, yaitu 80% untuk data training dan 20% untuk data testing, dengan hasil 10714 baris data untuk training dan 2679 baris data untuk testing, masing-masing memiliki 13 fitur. Hasil pembagian ini sudah sesuai proporsi dan jumlah total datanya tetap 13393 baris, sehingga data siap digunakan untuk proses pembuatan model klasifikasi selanjutnya.
"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Load data
df = pd.read_csv('bodyPerformance.csv')

# Menambahkan kolom target 'Performa_Baik' berdasarkan broad jump_cm
df['Performa_Baik'] = (df['broad jump_cm'] >= 220).astype(int)

# Melakukan One-Hot Encoding pada kolom kategorikal (gender dan class)
df_encoded = pd.get_dummies(df.drop(columns=['broad jump_cm']), drop_first=True)

# Menentukan fitur (X) dan target (y)
X = df_encoded.drop(columns=['Performa_Baik'])
y = df_encoded['Performa_Baik']

# Membagi data menjadi training dan testing (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Menampilkan dimensi data hasil split
print(f"üîπ X_train: {X_train.shape}, X_test: {X_test.shape}")
print(f"üîπ y_train: {y_train.shape}, y_test: {y_test.shape}")

"""# **Modeling**

**Model Random Forest**

Pada tahap ini, dibuat model Random Forest Classifier untuk memprediksi apakah performa lompat jauh seseorang baik atau tidak berdasarkan data yang sudah diproses. Model dilatih menggunakan data training, lalu digunakan untuk memprediksi data testing. Hasil prediksi dievaluasi menggunakan akurasi, classification report, dan confusion matrix untuk melihat seberapa baik model dalam membedakan performa lompat jauh yang baik dan kurang baik. Proses ini dilakukan untuk mengetahui seberapa akurat model dalam melakukan klasifikasi pada data yang belum pernah dilihat sebelumnya.
"""

# Membuat model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Melatih model dengan data training
rf_model.fit(X_train, y_train)

# Melakukan prediksi pada data testing
y_pred = rf_model.predict(X_test)

# Menghitung akurasi prediksi
accuracy = accuracy_score(y_test, y_pred)
print(f"üéØ Akurasi Model Random Forest: {accuracy:.2f}")

# Menampilkan classification report
print("\nüìä Classification Report:")
print(classification_report(y_test, y_pred))

# Menampilkan confusion matrix
print("\nüìù Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""**Model Logistic Regression**

*  Model Logistic Regression dibuat dan dilatih menggunakan data training.
*   Model memprediksi nilai Performa_Baik di data testing.

*   Hasilnya dievaluasi dengan akurasi, classification report, dan confusion matrix untuk melihat performa model klasifikasi.
"""

# Inisialisasi model Logistic Regression
logreg_model = LogisticRegression(max_iter=1000, random_state=42)

# Melatih model dengan data training
logreg_model.fit(X_train, y_train)

# Melakukan prediksi terhadap data testing
y_pred_logreg = logreg_model.predict(X_test)

# Menghitung akurasi prediksi
accuracy_logreg = accuracy_score(y_test, y_pred_logreg)
print(f"üéØ Akurasi Model Logistic Regression: {accuracy_logreg:.2f}")

# Menampilkan classification report
print("\nüìä Classification Report:")
print(classification_report(y_test, y_pred_logreg))

# Menampilkan confusion matrix
print("\nüìù Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_logreg))

"""**Model SVM**

menjelaskan langkah-langkah untuk menggunakan Support Vector Machine (SVM) dengan kernel linear dalam konteks klasifikasi. Tujuannya adalah untuk membangun sebuah model yang dapat mempelajari pola dalam data pelatihan dan kemudian digunakan untuk memprediksi kelas dari data yang belum dilihat sebelumnya (data uji).


1.   Inisialisasi Model: Menyiapkan model SVM dengan kernel linear yang digunakan untuk memisahkan data ke dalam dua kelas.
2.   Melatih Model: Menggunakan data pelatihan untuk "mengajarkan" model SVM cara membedakan antara kelas-kelas dalam data.
1.   Memprediksi: Setelah model dilatih, digunakan untuk memprediksi kelas dari data uji berdasarkan pola yang sudah dipelajari.
"""

# Inisialisasi model SVM dengan kernel linear
svm_model = SVC(kernel='linear', random_state=42)

# Melatih model SVM menggunakan data pelatihan
svm_model.fit(X_train, y_train)

# Memprediksi data uji
y_pred_svm = svm_model.predict(X_test)

"""# **EVALUASI MODEL**"""

# Fungsi untuk menilai performa model
def assess_model_performance(model, X_test, y_test, model_name):
    # Memprediksi label untuk data uji
    y_predictions = model.predict(X_test)

    # Menampilkan evaluasi model
    print(f"\nüìå Evaluasi {model_name}:")
    print("‚úÖ Skor Akurasi:")
    print(accuracy_score(y_test, y_predictions))

    # Menampilkan classification report
    print("\nüìä Laporan Klasifikasi:")
    print(classification_report(y_test, y_predictions))

    # Menampilkan confusion matrix
    print("\nüß© Confusion Matrix:")
    confusion_mat = confusion_matrix(y_test, y_predictions)
    print(confusion_mat)

    # Visualisasi heatmap untuk matriks kebingungannya
    plt.figure(figsize=(5, 4))
    sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='pink')
    plt.title(f'Confusion Matrix - {model_name}')
    plt.xlabel('Hasil Prediksi')
    plt.ylabel('Label Asli')
    plt.show()

# Menilai performa model SVM
assess_model_performance(svm_model, X_test, y_test, "SVM")

# Menilai performa model Logistic Regression
assess_model_performance(logreg_model, X_test, y_test, "Logistic Regression")

# Menilai performa model Random Forest
assess_model_performance(rf_model, X_test, y_test, "Random Forest")

"""Dari hasil evaluasi model SVM, Logistic Regression, dan Random Forest, berikut adalah beberapa insight yang dapat diambil:

1. Akurasi Model
SVM: Akurasi 87.01%

Logistic Regression: Akurasi 87.31%

Random Forest: Akurasi 87.42%


---


Insight: Ketiga model memiliki akurasi yang sangat mirip, berkisar di sekitar 87%. Ini menunjukkan bahwa ketiga model bekerja dengan baik dalam hal prediksi keseluruhan. Meskipun akurasi sedikit lebih tinggi pada Random Forest, perbedaan ini sangat kecil, sehingga model mana yang dipilih mungkin lebih dipengaruhi oleh faktor lain seperti interpretabilitas, kecepatan pelatihan, atau kebutuhan untuk menangani data yang lebih kompleks.


---


2. Laporan Klasifikasi
Precision untuk kelas 0 (negatif) cukup tinggi pada ketiga model, yang menunjukkan bahwa model secara konsisten mengidentifikasi kelas negatif dengan baik.

Recall untuk kelas 0 sedikit lebih rendah daripada precision, tetapi masih dalam angka yang sangat baik (sekitar 91-92%).

Precision dan Recall untuk kelas 1 (positif) lebih rendah, terutama untuk SVM dan Logistic Regression. Precision kelas 1 berkisar antara 0.75 hingga 0.77, sedangkan recall kelas 1 sekitar 0.76-0.77. Ini menunjukkan bahwa model cenderung memprediksi kelas 1 dengan agak berhati-hati dan memiliki beberapa kesalahan prediksi untuk kelas positif.


---


Insight:

Kelas 1 (positif) lebih sulit diprediksi dengan baik, yang terlihat dari recall dan precision yang lebih rendah dibandingkan dengan kelas 0. Ini menunjukkan bahwa model sedikit lebih sering salah memprediksi kelas positif sebagai negatif (false negatives).

F1-Score untuk kelas 1 berkisar antara 0.76 pada ketiga model, yang menunjukkan ada ruang untuk perbaikan pada prediksi kelas 1.


---


3. Matriks Kebingungannya (Confusion Matrix)
Matriks kebingungan memberikan gambaran lebih rinci mengenai kesalahan model:

SVM:

True Positives (TP) = 548, False Positives (FP) = 183

False Negatives (FN) = 165, True Negatives (TN) = 1783

Logistic Regression:

True Positives (TP) = 551, False Positives (FP) = 178

False Negatives (FN) = 162, True Negatives (TN) = 1788

Random Forest:

True Positives (TP) = 541, False Positives (FP) = 165

False Negatives (FN) = 172, True Negatives (TN) = 1801


---


Insight:

False Positives (FP): Ketiga model menghasilkan jumlah false positives yang cukup besar, dengan SVM menghasilkan FP terbanyak (183). Hal ini menunjukkan bahwa model sedikit sering salah mengklasifikasikan kelas negatif sebagai positif, meskipun ketiga model menunjukkan hasil yang mirip.

False Negatives (FN): Random Forest memiliki FN yang lebih tinggi (172), yang berarti model ini lebih sering melewatkan kelas positif dibandingkan dengan SVM dan Logistic Regression (di mana FN lebih rendah, sekitar 165 dan 162).

True Positives (TP) dan True Negatives (TN): Secara keseluruhan, ketiga model cukup baik dalam mengidentifikasi True Positives (TP) dan True Negatives (TN), meskipun Random Forest sedikit lebih sering mengidentifikasi FN (kesalahan klasifikasi positif) dibandingkan dengan dua model lainnya.


---


4. Perbandingan Model
SVM: SVM cenderung menghasilkan lebih banyak False Positives (183), yang bisa menunjukkan bahwa model ini sedikit lebih agresif dalam memprediksi kelas positif. Namun, akurasi dan F1-Score tetap cukup baik.

Logistic Regression: Model ini lebih stabil dan juga menghasilkan hasil yang sangat mirip dengan SVM, dengan sedikit lebih rendah dalam recall untuk kelas positif. Ini memberikan gambaran bahwa Logistic Regression cukup efisien dalam beberapa kasus.

Random Forest: Meskipun Random Forest sedikit lebih baik dalam hal akurasi (87.42%), ia menghasilkan lebih banyak False Negatives dibandingkan dengan dua model lainnya. Ini bisa menjadi masalah jika kelas positif sangat penting untuk aplikasi Anda.


---


5. Kesimpulan
Model terbaik secara keseluruhan: Meskipun perbedaan antara ketiga model sangat kecil, Random Forest sedikit lebih unggul dalam hal akurasi total, meskipun menghasilkan lebih banyak False Negatives. Jika kelas positif lebih penting dalam konteks aplikasi Anda, model ini mungkin perlu penyesuaian lebih lanjut.

Pengoptimalan model: Untuk meningkatkan recall dan precision pada kelas 1, teknik seperti penyesuaian threshold, SMOTE (Synthetic Minority Over-sampling Technique), atau class balancing dapat membantu model untuk lebih sensitif terhadap kelas positif.
"""